
<img width="1024" height="1024" alt="Generated Image September 22, 2025 - 12_30PM" src="https://github.com/user-attachments/assets/76efd099-933b-4dd3-8a8b-d4c3e56ed7d5" />
/d√©p√¥t" GitHub 

# üêâ Dragon CLI - Votre Assistant IA Personnel dans le Terminal

[![NPM Version](https://img.shields.io/npm/v/dragon-cli.svg?style=for-the-badge)](https://www.npmjs.com/package/dragon-cli)
[![NPM Downloads](https://img.shields.io/npm/dm/dragon-cli.svg?style=for-the-badge)](https://www.npmjs.com/package/dragon-cli)
[![Licence](https://img.shields.io/github/license/Mauricio-100/Dragon?style=for-the-badge)](./LICENSE)

**Dragon CLI est un outil en ligne de commande qui transforme votre terminal en un dialogue intelligent avec une IA. Au lieu de vous souvenir de commandes complexes, d√©crivez simplement ce que vous voulez faire. Dragon se connecte √† *votre propre serveur IA* pour une exp√©rience rapide, s√©curis√©e et enti√®rement sous votre contr√¥le.**

---

<p align="center">
  <i>"Cr√©e un serveur express simple dans un fichier app.js"</i><br>
  <i>"Affiche les 5 derniers commits de ce projet"</i><br>
  <i>"Installe la d√©pendance 'chalk' avec npm"</i>
</p>

---

## Architecture : Comment √ßa fonctionne ?

La puissance de Dragon r√©side dans son architecture d√©coupl√©e. Le CLI est intentionnellement l√©ger et ne contient aucune logique IA. Il agit comme une interface s√©curis√©e vers votre propre cerveau distant.

1.  **Vous** donnez un ordre en langage naturel √† Dragon CLI.
2.  **Dragon CLI** envoie cet ordre de mani√®re s√©curis√©e √† votre serveur personnel.
3.  **Votre Serveur IA** (que vous contr√¥lez) re√ßoit l'ordre, le met en forme dans un prompt syst√®me, et l'envoie √† l'API de Gemini.
4.  La r√©ponse de l'IA est renvoy√©e √† votre serveur, qui la formate en JSON et la transmet √† Dragon CLI.
5.  **Dragon CLI** vous pr√©sente le plan d'action et attend votre confirmation avant d'ex√©cuter quoi que ce soit.

Cette approche garantit que vos cl√©s API secr√®tes ne sont **jamais** expos√©es sur la machine cliente.

## üöÄ Guide de D√©marrage Complet en 3 √âtapes

Pour utiliser Dragon, vous avez besoin de ses deux composantes : le cerveau (le serveur) et le corps (le CLI).

### √âtape 1 : D√©ployer Votre Propre Serveur IA (Le Cerveau)

Le CLI a besoin d'une URL √† qui parler. Nous fournissons un serveur template pr√™t √† √™tre d√©ploy√© sur des plateformes comme Render.

1.  **Cliquez sur ce lien pour cr√©er votre propre copie du serveur :**
    *   **[Utiliser ce template de serveur IA](https://github.com/Mauricio-100/Dragon-Server-Template)** <!-- Remplacez par le lien vers VOTRE template de serveur -->

2.  **D√©ployez ce nouveau d√©p√¥t sur un service d'h√©bergement** comme [Render](https://render.com/), Vercel, ou Heroku. Le d√©ploiement est g√©n√©ralement automatique.

3.  **Configurez les variables d'environnement sur la plateforme d'h√©bergement :** Votre serveur aura besoin de conna√Ætre votre cl√© API secr√®te de Google. Dans les param√®tres de votre service sur Render, ajoutez une variable d'environnement :
    *   `GEMINI_API_KEY`: Votre cl√© API que vous obtenez depuis Google AI Studio.
    *   `SECRET_KEY`: Une longue cha√Æne de caract√®res al√©atoires que vous inventez, pour s√©curiser les tokens de votre serveur.

4.  Une fois le d√©ploiement termin√©, Render vous donnera une URL publique. **Notez cette URL**, vous en aurez besoin.

### √âtape 2 : Installer Dragon CLI (Le Corps)

Maintenant que le cerveau est en ligne, installez le client sur votre machine.

```bash
npm install -g dragon-cli```
<!-- Remplacez "dragon-cli" par le nom final de votre paquet sur npm -->
```
### √âtape 3 : Configurer la Connexion

Cr√©ez un pont entre le corps et le cerveau.

1.  Cr√©ez un fichier `.env` dans votre r√©pertoire personnel. C'est le moyen le plus s√ªr de stocker vos informations de connexion.
    ```bash
    nano ~/.env
    ```

2.  Ajoutez-y les informations de votre serveur. Le `BEARER_TOKEN` est la cl√© API (`sk-...`) que **votre propre serveur** a g√©n√©r√©e pour vous (via l'endpoint `/user/api-token` par exemple).

    ```env
    # L'URL de votre serveur d√©ploy√© √† l'√©tape 1
    SERVER_URL="https://votre-serveur-sur-render.onrender.com/chat-direct"
    ```

    # La cl√© API g√©n√©r√©e par VOTRE serveur pour vous authentifier
    .oso
    ```
    BEARER_TOKEN="sk-sxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
    ```

4.  Sauvegardez le fichier.

## üéÆ Utilisation

Tout est pr√™t ! R√©veillez le Dragon :

```bash
drn
```
### Ex de Server utiliser 

```bash
// ==========================
//  IMPORTS DES MODULES
// ==========================
import express from 'express';
import { GoogleGenerativeAI } from '@google/generative-ai';
import dotenv from 'dotenv';
import cors from 'cors';

// ==========================
//  CONFIGURATION INITIALE
// ==========================
dotenv.config();
const app = express();

// Middlewares
app.use(express.json()); // Pour comprendre le JSON envoy√© par le Dragon
app.use(cors());         // Pour autoriser les requ√™tes (bonne pratique)

const PORT = process.env.PORT || 10000;
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const INTERNAL_SECRET_TOKEN = process.env.INTERNAL_SECRET_TOKEN;

// Validation : le serveur ne d√©marrera pas si les secrets ne sont pas d√©finis
if (!GEMINI_API_KEY || !INTERNAL_SECRET_TOKEN) {
  console.error("ERREUR: GEMINI_API_KEY et INTERNAL_SECRET_TOKEN doivent √™tre d√©finis dans le fichier .env");
  process.exit(1); // Arr√™te le processus
}

// ==========================
//  CLIENT IA GEMINI
// ==========================
const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
// Nous utilisons "gemini-pro", le mod√®le le plus stable et universellement disponible.
const model = genAI.getGenerativeModel({ model: "gemini-pro" });


// ==========================
//  S√âCURIT√â (MIDDLEWARE D'AUTHENTIFICATION)
// ==========================
function apiAuth(req, res, next) {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1]; // Extrait le token "Bearer <token>"

  if (!token) {
    return res.status(401).json({ error: "Acc√®s non autoris√© : token manquant." });
  }

  if (token !== INTERNAL_SECRET_TOKEN) {
    return res.status(403).json({ error: "Acc√®s interdit : token invalide." });
  }

  next(); // Si le token est bon, on continue vers la route principale
}


// ==========================
//  LA ROUTE PRINCIPALE DE L'IA
// ==========================
// C'est ici que le Dragon CLI envoie ses requ√™tes.
app.post('/chat-direct', apiAuth, async (req, res) => {
  try {
    const { message } = req.body; // Le "message" est le prompt complet envoy√© par le Dragon

    if (!message) {
      return res.status(400).json({ error: "Le champ 'message' est requis." });
    }

    // On envoie le prompt directement √† Gemini
    const result = await model.generateContent(message);
    const response = await result.response;
    const aiTextResponse = response.text();

    // On renvoie la r√©ponse de l'IA au Dragon, dans un champ "reply"
    res.json({ reply: aiTextResponse });

  } catch (error) {
    console.error("Erreur lors de la communication avec l'API Gemini :", error);
    res.status(500).json({ error: `Erreur interne du serveur : ${error.message}` });
  }
});


// ==========================
//  D√âMARRAGE DU SERVEUR
// ==========================
app.listen(PORT, () => {
  console.log(`üöÄ Le cerveau du Dragon est en ligne et √©coute sur le port ${PORT}`);
});
```
##### L'interface appara√Ætra, et vous pourrez commencer √† dialoguer avec votre nouvel assistant. Pour quitter, tapez exit.

üõ°Ô∏è Un Mot sur la S√©curit√©
La s√©curit√© est primordiale. Dragon ne prendra jamais l'initiative d'ex√©cuter une commande ou de modifier un fichier. Chaque plan d'action g√©n√©r√© par l'IA vous est d'abord soumis pour approbation. Vous avez toujours le contr√¥le final.

Approuvez-vous cette action ? (Ex√©cuter: git log -n 5) (y/n) >

üìú Licence
Distribu√© sous la licence MIT. Voir LICENSE pour plus d'informations.
